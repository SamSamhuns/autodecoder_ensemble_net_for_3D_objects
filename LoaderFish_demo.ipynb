{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T04:24:32.626437Z",
     "start_time": "2020-05-18T04:24:31.879008Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Try importing tqdm notebook\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"tdqm.notebook not found. Try updating tdqm. Reverting to base tqdm\", e)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import joblib  # To save models\n",
    "from sklearn.metrics import hinge_loss\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# CUSTOM IMPORTS\n",
    "import LoaderFish  # function to gen custom point clouds (Wang et. al)\n",
    "\n",
    "# utility functions\n",
    "from src.utils import (\n",
    "    chamfer_loss,\n",
    "    HyperParameter,\n",
    "    DirectorySetting,\n",
    ")\n",
    "\n",
    "# models\n",
    "from src.models import AutoDecoder, CompNet, EnsembleCompNet\n",
    "\n",
    "# datasets\n",
    "from src.datasets import PointDriftDS, EncodingDS, PointNetDS\n",
    "\n",
    "# train and test modules\n",
    "from src.trainer import (\n",
    "    find_encoding,\n",
    "    train_decoder,\n",
    "    eval_decoder,\n",
    "    train_compnet,\n",
    "    eval_compnet,\n",
    ")\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cuda device and SEED val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    # inbuilt cudnn auto-tuner searches for best algorithm for hardware\n",
    "    # cuddn.benchmark should be set to True when our input size does not vary\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"GPU training available\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"Index of CUDA device in use is {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"GPU training NOT available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Can only train on CPU\")\n",
    "\n",
    "DEBUG = True\n",
    "SEED = 17 * 19\n",
    "\n",
    "HP = HyperParameter(\n",
    "    epochs=10,\n",
    "    l2_reg=None,\n",
    "    batch_size=16,\n",
    "    num_point_cloud=3,\n",
    "    encoding_iters=1000,\n",
    "    encoding_size=256,\n",
    ")\n",
    "DS = DirectorySetting()\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     22,
     38
    ]
   },
   "outputs": [],
   "source": [
    "class AutoDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoDecoder NN to learn point drift (latent encoding) between two 3D shapes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding_dim=256, point_dim=3):\n",
    "        super(AutoDecoder, self).__init__()\n",
    "        self.fc1 = nn.Conv1d(encoding_dim + point_dim, 128, 1)\n",
    "        self.fc2 = nn.Conv1d(128, 64, 1)\n",
    "        self.fc3 = nn.Conv1d(64, point_dim, 1)\n",
    "\n",
    "    def forward(self, X, encoding):\n",
    "        num_points = X.shape[-1]  # num of points in each shape\n",
    "        enc = encoding.unsqueeze(-1).repeat(1, 1, num_points)\n",
    "        X_enc = torch.cat([X, enc], 1)\n",
    "        X_enc = F.leaky_relu(self.fc1(X_enc))\n",
    "        X_enc = F.leaky_relu(self.fc2(X_enc))\n",
    "\n",
    "        # Return the drift from obj X determined by the latent encoding\n",
    "        return X + self.fc3(X_enc)\n",
    "\n",
    "\n",
    "class CompNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Ingests the latent encoding of two 3D objects\n",
    "    and outputs the similarity score\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding_size=256):\n",
    "        super(CompNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(encoding_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, encoding):\n",
    "        X = F.leaky_relu(self.fc1(encoding))\n",
    "        return torch.sigmoid(self.fc2(X))\n",
    "\n",
    "\n",
    "class EnsembleCompNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Ingests the latent encoding of two 3D objects\n",
    "    and outputs the similarity score using an ensemble of CompNets\n",
    "    Stacked Ensemble\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, comp_net=CompNet, num_ensemble=5, encoding_dim=256, seed_val=SEED\n",
    "    ):\n",
    "        \"\"\"\n",
    "        if comp_net is a module, EnsembleCompNet creates num_ensemble*comp_net NN modules\n",
    "        if comp_net is a list of modules, EnsembleCompNet iterates through comp_net to get the NN modules\n",
    "        \"\"\"\n",
    "        super(EnsembleCompNet, self).__init__()\n",
    "        self.ensemble_compnet = nn.ModuleList()\n",
    "\n",
    "        if isinstance(comp_net, list):\n",
    "            if num_ensemble != len(comp_net):\n",
    "                raise IndexError(\n",
    "                    f\"Length of comp_nets: {len(comp_net)} and num_ensemble: {num_ensemble} do not match\"\n",
    "                )\n",
    "            comp_net_list = comp_net\n",
    "            for i in range(num_ensemble):\n",
    "                self.ensemble_compnet.append(comp_net_list[i])\n",
    "        else:\n",
    "            for i in range(num_ensemble):\n",
    "                torch.manual_seed(seed_val * i + 1)\n",
    "                if use_cuda:\n",
    "                    torch.cuda.manual_seed(seed_val * i + 1)\n",
    "                self.ensemble_compnet.append(comp_net(encoding_dim))\n",
    "        self.final = nn.Linear(num_ensemble, 1)\n",
    "\n",
    "    def forward(self, encoding):\n",
    "        \"\"\"Returns the final value of the results after a nn.Linear layer\"\"\"\n",
    "        total_pred = torch.cat([net(encoding) for net in self.ensemble_compnet])\n",
    "        total_pred = total_pred.reshape(-1, len(self.ensemble_compnet))\n",
    "\n",
    "        return torch.sigmoid(self.final(total_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Modules and DataLoader implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     17,
     22,
     53
    ]
   },
   "outputs": [],
   "source": [
    "class PointNetDS(Dataset):\n",
    "    \"\"\"\n",
    "    Create train dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, sampling_interval=3):\n",
    "        # sample every sampling_interval-th point to speed up\n",
    "        self.data = data.transpose((0, 2, 1))[:, :, ::sampling_interval]\n",
    "        self.data = torch.from_numpy(self.data).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class PointDriftDS(Dataset):\n",
    "    \"\"\"\n",
    "    Pairs each shape with one shape from the same class and one shape from a different class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, labels, sampling_interval=3):\n",
    "        # sample every sampling_interval-th point to speed up\n",
    "        self.data = data.transpose((0, 2, 1))[:, :, ::sampling_interval]\n",
    "        self.labels = labels.squeeze()\n",
    "\n",
    "        self.same_cls = []\n",
    "        self.diff_cls = []\n",
    "        idx_arr = np.arange(self.data.shape[0])\n",
    "        same_idx = []\n",
    "        diff_idx = []\n",
    "        for i in range(self.labels.max() + 1):\n",
    "            same_idx.append(idx_arr[self.labels == i])\n",
    "            diff_idx.append(idx_arr[self.labels != i])\n",
    "        for i in range(data.shape[0]):\n",
    "            same = same_idx[self.labels[i]]\n",
    "            diff = diff_idx[self.labels[i]]\n",
    "            self.same_cls.append(same[random.randint(0, len(same) - 1)])\n",
    "            self.diff_cls.append(diff[random.randint(0, len(diff) - 1)])\n",
    "        self.data = torch.from_numpy(self.data).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx]\n",
    "        same_cls_data = self.data[self.same_cls[idx]]\n",
    "        diff_cls_data = self.data[self.diff_cls[idx]]\n",
    "\n",
    "        return X, same_cls_data, diff_cls_data, idx\n",
    "\n",
    "\n",
    "class EncodingDS(Dataset):\n",
    "    \"\"\"\n",
    "    Generate encoding for each pair of shapes in the PointDriftDS\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, PDDS, autodecoder, latent_size=256):\n",
    "        self.PointDriftDS = PDDS\n",
    "        self.autodecoder = autodecoder\n",
    "        self.latent_size = latent_size\n",
    "        self.same_cls = torch.zeros((len(self.PointDriftDS), latent_size))\n",
    "        self.diff_cls = torch.zeros((len(self.PointDriftDS), latent_size))\n",
    "\n",
    "    def train_encodings(self, num_iterations=50, lr=0.01, l2_reg=False, batch_size=16):\n",
    "        dl = DataLoader(self.PointDriftDS, batch_size=batch_size, shuffle=False)\n",
    "        i = 0\n",
    "        batch_cnt = 0\n",
    "        same_cls_loss = 0.0\n",
    "        diff_cls_loss = 0.0\n",
    "        self.autodecoder.eval()\n",
    "\n",
    "        for batch_idx, (x, y, z, idx) in enumerate(dl):\n",
    "            j = i + len(idx)\n",
    "            loss, encoding = find_encoding(\n",
    "                x,\n",
    "                y,\n",
    "                self.autodecoder,\n",
    "                encoding_iters=num_iterations,\n",
    "                encoding_size=self.latent_size,\n",
    "                lr=lr,\n",
    "                l2_reg=l2_reg,\n",
    "            )\n",
    "            same_cls_loss += loss\n",
    "            self.same_cls[i:j] = encoding\n",
    "            loss, encoding = find_encoding(\n",
    "                x,\n",
    "                z,\n",
    "                self.autodecoder,\n",
    "                encoding_iters=num_iterations,\n",
    "                encoding_size=self.latent_size,\n",
    "                lr=lr,\n",
    "                l2_reg=l2_reg,\n",
    "            )\n",
    "            diff_cls_loss += loss\n",
    "            self.diff_cls[i:j] = encoding\n",
    "\n",
    "            i = j\n",
    "            batch_cnt += 1\n",
    "        print(\"Encodings trained\")\n",
    "        return (\n",
    "            self.same_cls,\n",
    "            self.diff_cls,\n",
    "            same_cls_loss / batch_cnt,\n",
    "            diff_cls_loss / batch_cnt,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.PointDriftDS)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (*self.PointDriftDS[idx], self.same_cls[idx], self.diff_cls[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def find_encoding(\n",
    "    X, y, autodecoder, encoding_iters=300, encoding_size=256, lr=5e-4, l2_reg=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate the encoding (latent vector) for each data in X\n",
    "    \"\"\"\n",
    "\n",
    "    def _adjust_lr(initial_lr, optimizer, num_iters, decreased_by, adjust_lr_every):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iters // adjust_lr_every))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    decreased_by = 10\n",
    "    adjust_lr_every = encoding_iters // 2\n",
    "\n",
    "    encoding = (\n",
    "        torch.ones(X.shape[0], encoding_size)\n",
    "        .normal_(mean=0, std=1.0 / math.sqrt(encoding_size))\n",
    "        .cuda()\n",
    "    )\n",
    "\n",
    "    encoding.requires_grad = True\n",
    "    optimizer = torch.optim.Adam([encoding], lr=lr)\n",
    "    loss_num = 0\n",
    "\n",
    "    for i in range(encoding_iters):\n",
    "        autodecoder.eval()\n",
    "        _adjust_lr(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = autodecoder(X, encoding)\n",
    "        loss = chamfer_loss(y_pred, y, ps=y.shape[-1])\n",
    "\n",
    "        if l2_reg:\n",
    "            loss += 1e-4 * torch.mean(encoding.pow(2))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(i, loss.cpu().data.numpy(), encoding.norm())\n",
    "        loss_num = loss.cpu().data.numpy()\n",
    "\n",
    "    return loss_num, encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_decoder(\n",
    "    HP, DS, train_ds, test_ds=None, decoder=None, save_wt_fname=\"decoder.pth\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Default training is for 3D point dimensions\n",
    "\n",
    "    Suggested Settings\n",
    "        EPOCHS = 10\n",
    "        point_dim = 3\n",
    "        batch_size = 16\n",
    "        learning_rate = 0.001\n",
    "        encoding_size = 256\n",
    "\n",
    "    Set save_wt_fname to None to disable weight saves\n",
    "    \"\"\"\n",
    "    EPOCHS = HP.epochs\n",
    "    point_dim = HP.num_point_cloud\n",
    "    batch_size = HP.batch_size\n",
    "    encoding_size = HP.encoding_size\n",
    "    lr = HP.learning_rate\n",
    "\n",
    "    if decoder is None:\n",
    "        adnet = AutoDecoder(encoding_size, point_dim)\n",
    "    else:\n",
    "        adnet = decoder\n",
    "    adnet = adnet.cuda()\n",
    "\n",
    "    # encodings for same class transformation\n",
    "    same_encoding = torch.nn.Embedding(len(train_ds), encoding_size, max_norm=1.0)\n",
    "    # init encoding with Kaiming Initialization\n",
    "    torch.nn.init.normal_(\n",
    "        same_encoding.weight.data, 0.0, 1.0 / math.sqrt(encoding_size)\n",
    "    )\n",
    "\n",
    "    # encodings for different class transformation\n",
    "    diff_encoding = torch.nn.Embedding(len(train_ds), encoding_size, max_norm=1.0)\n",
    "    # init encoding with Kaiming Initialization\n",
    "    torch.nn.init.normal_(\n",
    "        diff_encoding.weight.data, 0.0, 1.0 / math.sqrt(encoding_size)\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\n",
    "                \"params\": adnet.parameters(),\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "            {\n",
    "                \"params\": same_encoding.parameters(),\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "            {\n",
    "                \"params\": diff_encoding.parameters(),\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    op_schedule = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    adnet = nn.DataParallel(adnet)\n",
    "    adnet.cuda()\n",
    "\n",
    "    data_loader_train = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(0, EPOCHS):\n",
    "        adnet.train()\n",
    "        same_total_loss = 0.0\n",
    "        diff_total_loss = 0.0\n",
    "\n",
    "        for batch_idx, (x, y, z, idx) in enumerate(data_loader_train):\n",
    "            optimizer.zero_grad()\n",
    "            x, y, z = x.cuda(), y.cuda(), z.cuda()\n",
    "            x, y, z = (Variable(x).float(), Variable(y).float(), Variable(z).float())\n",
    "            y_pred = adnet(x, same_encoding(torch.LongTensor(idx)))\n",
    "            loss_cham = chamfer_loss(y, y_pred, ps=y.shape[-1])\n",
    "            same_total_loss += loss_cham.data.cpu().numpy()\n",
    "            loss_cham.backward()\n",
    "\n",
    "            z_pred = adnet(x, diff_encoding(torch.LongTensor(idx)))\n",
    "            loss_cham = chamfer_loss(z, z_pred, ps=z.shape[-1])\n",
    "            diff_total_loss += loss_cham.data.cpu().numpy()\n",
    "            loss_cham.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "                print(f\"Epoch: {epoch}. batch_idx: {batch_idx}\")\n",
    "                print(\"Loss: \", same_total_loss / 100, diff_total_loss / 100)\n",
    "                same_total_loss = 0.0\n",
    "                diff_total_loss = 0.0\n",
    "        op_schedule.step(epoch)\n",
    "\n",
    "        if test_ds is not None and epoch % 5 == 0:\n",
    "            print(\"Eval: \", eval_decoder(adnet, test_ds, batch_size=batch_size))\n",
    "\n",
    "    if save_wt_fname is not None:\n",
    "        torch.save(\n",
    "            adnet.module.state_dict(),\n",
    "            DS.AUTODECODER_TRAINED_WEIGHT_DIR + \"/\" + save_wt_fname,\n",
    "        )\n",
    "    return adnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def eval_decoder(decoder, eval_ds, batch_size=16):\n",
    "    decoder.eval()\n",
    "    encoding_ds = EncodingDS(eval_ds, decoder)\n",
    "    return encoding_ds.train_encodings(\n",
    "        num_iterations=10, lr=0.05, batch_size=batch_size\n",
    "    )[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_svm_whole_dset(HP, DS, train_ds, save_wt_fname=\"svm_whole.pkl\"):\n",
    "    \"\"\"\n",
    "    Train the SVM\n",
    "\n",
    "    Suggested Parameters\n",
    "    batch_size=16\n",
    "    \"\"\"\n",
    "    batch_size = HP.batch_size\n",
    "    data_loader_train = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    X, y = None, None\n",
    "    # Combine the entire dataset\n",
    "    for batch_idx, (_x, _y, _z, _idx, same_cls, diff_cls) in enumerate(\n",
    "        data_loader_train\n",
    "    ):\n",
    "        same_cls, diff_cls = same_cls.detach().numpy(), diff_cls.detach().numpy()\n",
    "        same_target, diff_target = (\n",
    "            np.ones(same_cls.shape[0]),\n",
    "            np.zeros(diff_cls.shape[0]),\n",
    "        )\n",
    "\n",
    "        if X is None and y is None:\n",
    "            X = np.concatenate([same_cls, diff_cls], axis=0)\n",
    "            y = np.concatenate([same_target, diff_target], axis=0)\n",
    "        else:\n",
    "            X = np.concatenate([X, same_cls, diff_cls], axis=0)\n",
    "            y = np.concatenate([y, same_target, diff_target], axis=0)\n",
    "\n",
    "    rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "    sgd_clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "\n",
    "    X_features = rbf_feature.fit_transform(X)\n",
    "    sgd_clf.fit(X_features, y)\n",
    "    y_pred = sgd_clf.predict(X_features)\n",
    "\n",
    "    print(f\"Total Hinge Loss: {hinge_loss(y, y_pred)}\")\n",
    "    if save_wt_fname is not None:\n",
    "        _ = joblib.dump(\n",
    "            sgd_clf, DS.CLASSIFIER_TRAINED_WEIGHT_DIR + \"/\" + save_wt_fname, compress=9\n",
    "        )\n",
    "    return sgd_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def eval_svm_whole_dset(svm_clf, test_ds, batch_size=16):\n",
    "    print(len(test_ds))\n",
    "    rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "    X, y = None, None\n",
    "    # Combine the entire dataset\n",
    "    for batch_idx, (_x, _y, _z, _idx, same_cls, diff_cls) in enumerate(\n",
    "        data_loader_train\n",
    "    ):\n",
    "        same_cls, diff_cls = same_cls.detach().numpy(), diff_cls.detach().numpy()\n",
    "        same_target, diff_target = (\n",
    "            np.ones(same_cls.shape[0]),\n",
    "            np.zeros(diff_cls.shape[0]),\n",
    "        )\n",
    "\n",
    "        if X is None and y is None:\n",
    "            X = np.concatenate([same_cls, diff_cls], axis=0)\n",
    "            y = np.concatenate([same_target, diff_target], axis=0)\n",
    "        else:\n",
    "            X = np.concatenate([X, same_cls, diff_cls], axis=0)\n",
    "            y = np.concatenate([y, same_target, diff_target], axis=0)\n",
    "\n",
    "    X_features = rbf_feature.fit_transform(X)\n",
    "    y_pred = svm_clf.predict(X_features)\n",
    "    y, y_pred = y.astype(int), y_pred.astype(int)\n",
    "\n",
    "    same_corr_cnt = np.sum(y_pred & y)\n",
    "    same_incorr_cnt = np.sum(y & (y_pred ^ 1))\n",
    "    diff_corr_cnt = np.sum((y ^ 1) & (y_pred ^ 1))\n",
    "    diff_incorr_cnt = np.sum((y ^ 1) & y_pred)\n",
    "\n",
    "    total_loss = hinge_loss(y, y_pred)\n",
    "    if batch_idx % 100 == 0:\n",
    "        print(f\"Batch_idx: {batch_idx}\")\n",
    "        print(\"Cur loss: \", total_loss)\n",
    "\n",
    "    precision = same_corr_cnt / (same_corr_cnt + diff_incorr_cnt)\n",
    "    recall = same_corr_cnt / (same_corr_cnt + same_incorr_cnt)\n",
    "    print(\"------------------ Evaluation Report ------------------\")\n",
    "    print(f\"After {len(test_ds)} test points\")\n",
    "    print(f\"Total Accuracy: {(same_corr_cnt + diff_corr_cnt) / (2 * len(test_ds))}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Metrics for the same class:\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {(2 * precision * recall) / (precision + recall)}\")\n",
    "\n",
    "    precision = diff_corr_cnt / (diff_corr_cnt + same_incorr_cnt)\n",
    "    recall = diff_corr_cnt / (diff_corr_cnt + diff_incorr_cnt)\n",
    "    print()\n",
    "    print(\"Metrics for the diff class:\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {(2 * precision * recall) / (precision + recall)}\")\n",
    "\n",
    "    return (\n",
    "        total_loss,\n",
    "        same_corr_cnt,\n",
    "        diff_corr_cnt,\n",
    "        same_incorr_cnt,\n",
    "        diff_incorr_cnt,\n",
    "        len(test_ds),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_compnet(\n",
    "    HP, DS, train_ds, test_ds=None, compnet=None, save_wt_fname=\"compnet.pth\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the CompNet\n",
    "\n",
    "    Suggested Parameters\n",
    "    EPOCHS=10\n",
    "    batch_size=16\n",
    "    encoding_size=256\n",
    "    learning_rate=0.001\n",
    "    \"\"\"\n",
    "    EPOCHS = HP.epochs\n",
    "    point_dim = HP.num_point_cloud\n",
    "    batch_size = HP.batch_size\n",
    "    encoding_size = HP.encoding_size\n",
    "    lr = HP.learning_rate\n",
    "\n",
    "    if compnet is None:\n",
    "        cpnet = CompNet(encoding_size=encoding_size)\n",
    "    else:\n",
    "        cpnet = compnet\n",
    "    cpnet = cpnet.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(cpnet.parameters(), lr=lr)\n",
    "    op_schedule = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    cpnet = nn.DataParallel(cpnet)\n",
    "    cpnet.cuda()\n",
    "\n",
    "    data_loader_train = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    for epoch in range(EPOCHS):\n",
    "        same_total_loss = 0.0\n",
    "        diff_total_loss = 0.0\n",
    "        cpnet.train()\n",
    "        for batch_idx, (x, y, z, idx, same_cls, diff_cls) in enumerate(\n",
    "            data_loader_train\n",
    "        ):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            same_cls, diff_cls = same_cls.cuda(), diff_cls.cuda()\n",
    "            same_cls, diff_cls = Variable(same_cls).float(), Variable(diff_cls).float()\n",
    "\n",
    "            same_pred = cpnet(same_cls)\n",
    "            same_target = torch.ones(same_pred.shape).float().cuda()\n",
    "            same_loss = loss_fn(same_pred, same_target)\n",
    "            same_loss.backward()\n",
    "            same_total_loss += same_loss.data.cpu().numpy()\n",
    "\n",
    "            diff_pred = cpnet(diff_cls)\n",
    "            diff_target = torch.zeros(diff_pred.shape).float().cuda()\n",
    "            diff_loss = loss_fn(diff_pred, diff_target)\n",
    "            diff_loss.backward()\n",
    "            diff_total_loss += diff_loss.data.cpu().numpy()\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "                print(f\"Epoch: {epoch}. batch_idx: {batch_idx}\")\n",
    "                print(\"Loss: \", same_total_loss / 100, diff_total_loss / 100)\n",
    "                same_total_loss = 0.0\n",
    "                diff_total_loss = 0.0\n",
    "        op_schedule.step(epoch)\n",
    "\n",
    "        if test_ds is not None and epoch % 5 == 0:\n",
    "            print(\"Eval: \", eval_compnet(cpnet, test_ds, batch_size=batch_size))\n",
    "\n",
    "    if save_wt_fname is not None:\n",
    "        torch.save(\n",
    "            cpnet.module.state_dict(),\n",
    "            DS.CLASSIFIER_TRAINED_WEIGHT_DIR + \"/\" + save_wt_fname,\n",
    "        )\n",
    "    return cpnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def eval_compnet(cpnet, test_ds, batch_size=16, pred_threshold=0.5):\n",
    "    cpnet.eval()\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    same_total_loss = 0.0\n",
    "    diff_total_loss = 0.0\n",
    "    batch_cnt = 0\n",
    "    same_corr_cnt = 0.0\n",
    "    diff_corr_cnt = 0.0\n",
    "    same_incorr_cnt = 0.0\n",
    "    diff_incorr_cnt = 0.0\n",
    "\n",
    "    for batch_idx, (x, y, z, idx, same_cls, diff_cls) in enumerate(test_dl):\n",
    "        batch_cnt += 1\n",
    "        same_cls, diff_cls = same_cls.cuda(), diff_cls.cuda()\n",
    "\n",
    "        same_pred = cpnet(same_cls)\n",
    "        same_target = torch.ones(same_pred.shape).float().cuda()\n",
    "        same_loss = loss_fn(same_pred, same_target)\n",
    "        same_total_loss += same_loss.data.cpu().numpy()\n",
    "\n",
    "        same_corr_cnt += np.sum(same_pred.detach().cpu().numpy() > pred_threshold)\n",
    "        same_incorr_cnt += np.sum(same_pred.detach().cpu().numpy() <= pred_threshold)\n",
    "\n",
    "        diff_pred = cpnet(diff_cls)\n",
    "        diff_target = torch.zeros(diff_pred.shape).float().cuda()\n",
    "        diff_loss = loss_fn(diff_pred, diff_target)\n",
    "        diff_total_loss += diff_loss.data.cpu().numpy()\n",
    "\n",
    "        diff_corr_cnt += np.sum(diff_pred.detach().cpu().numpy() < pred_threshold)\n",
    "        diff_incorr_cnt += np.sum(diff_pred.detach().cpu().numpy() >= pred_threshold)\n",
    "\n",
    "    precision = same_corr_cnt / (same_corr_cnt + diff_incorr_cnt)\n",
    "    recall = same_corr_cnt / (\n",
    "        same_corr_cnt + same_incorr_cnt\n",
    "    )  # same_corr_cnt / len(test_ds)\n",
    "    print(\"------------------ Evaluation Report ------------------\")\n",
    "    print(f\"Total Accuracy: {(same_corr_cnt + diff_corr_cnt) / (2 * len(test_ds))}\")\n",
    "    print(f\"After {batch_cnt} batches and {len(test_ds)} test points\")\n",
    "    print()\n",
    "\n",
    "    print(\"Metrics for the same class:\")\n",
    "    print(f\"Avg loss: {same_total_loss / batch_cnt}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {(2 * precision * recall) / (precision + recall)}\")\n",
    "\n",
    "    precision = diff_corr_cnt / (diff_corr_cnt + same_incorr_cnt)\n",
    "    recall = diff_corr_cnt / (\n",
    "        diff_corr_cnt + diff_incorr_cnt\n",
    "    )  # diff_corr_cnt / len(test_ds)\n",
    "    print()\n",
    "    print(\"Metrics for the diff class:\")\n",
    "    print(f\"Avg loss: {diff_total_loss / batch_cnt}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {(2 * precision * recall) / (precision + recall)}\")\n",
    "\n",
    "    return (\n",
    "        same_total_loss,\n",
    "        diff_total_loss,\n",
    "        same_corr_cnt,\n",
    "        diff_corr_cnt,\n",
    "        same_incorr_cnt,\n",
    "        diff_incorr_cnt,\n",
    "        batch_cnt,\n",
    "        len(test_ds),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "# Testing our AutoDecoder\n",
    "\n",
    "## Generating dummy Train and Test pair Fish shapes using LoaderFish (Wang et al. 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_before = []  # chamfer distance before registration\n",
    "CD_after = []  # chamfer distance after registration\n",
    "\n",
    "train_size = 20000  # size for training data\n",
    "test_size = 1000  # size for testing data\n",
    "deformation_list = [0.5]\n",
    "deformation = deformation_list[0]\n",
    "\n",
    "print(\".......Synthesizing Training Pairs......\")\n",
    "lf_train = LoaderFish.PointRegDataset(\n",
    "    total_data=train_size,\n",
    "    deform_level=deformation,\n",
    "    noise_ratio=0,\n",
    "    outlier_ratio=0,\n",
    "    outlier_s=False,\n",
    "    outlier_t=True,\n",
    "    noise_s=False,\n",
    "    noise_t=True,\n",
    "    missing_points=0,\n",
    "    miss_source=False,\n",
    "    miss_targ=True,\n",
    ")\n",
    "\n",
    "data_loader_lf_train = torch.utils.data.DataLoader(\n",
    "    lf_train, batch_size=16, shuffle=True\n",
    ")\n",
    "\n",
    "print(\".......Synthesizing Testing Pairs......\")\n",
    "lf_test = LoaderFish.PointRegDataset(\n",
    "    total_data=test_size,\n",
    "    deform_level=deformation,\n",
    "    noise_ratio=0,\n",
    "    outlier_ratio=0,\n",
    "    outlier_s=False,\n",
    "    outlier_t=True,\n",
    "    noise_s=False,\n",
    "    noise_t=True,\n",
    "    missing_points=0,\n",
    "    miss_source=False,\n",
    "    miss_targ=True,\n",
    ")\n",
    "\n",
    "data_loader_lf_test = torch.utils.data.DataLoader(lf_test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = next(iter(data_loader_lf_train))\n",
    "print(\n",
    "    len(sample_data), sample_data[0].shape, len(sample_data[0]), sample_data[0][0].shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the AutoDecoder on the sample generated LoaderFish dataset\n",
    "\n",
    "We generate encoding latent vectors for the shapes generated by the LoaderFish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Setup for loaderfish test\n",
    "EPOCHS = 4\n",
    "lr = 0.0001\n",
    "encoding_size = 256\n",
    "scheduler_gamma = 0.5\n",
    "scheduler_step_sz = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adnet = AutoDecoder(point_dim=2)\n",
    "adnet.cuda()\n",
    "\n",
    "encoding = torch.nn.Embedding(len(lf_train), encoding_size, max_norm=1.0)\n",
    "# init encoding with Kaiming Initialization\n",
    "torch.nn.init.normal_(encoding.weight.data, 0.0, 1.0 / math.sqrt(encoding_size))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": adnet.parameters(),\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        {\n",
    "            \"params\": encoding.parameters(),\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "op_schedule = optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=scheduler_step_sz, gamma=scheduler_gamma\n",
    ")\n",
    "\n",
    "# use multiple gpus\n",
    "adnet = nn.DataParallel(adnet)\n",
    "adnet.cuda()\n",
    "\n",
    "# Train the AutoDecoder adnet on the training data\n",
    "for epoch in range(EPOCHS):\n",
    "    adnet.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (X, y, theta, _, idx) in enumerate(data_loader_lf_train):\n",
    "        X, y, theta = X.cuda(), y.cuda(), theta.cuda()\n",
    "        X, y, theta = Variable(X).float(), Variable(y).float(), Variable(theta).float()\n",
    "        y_pred = adnet(X, encoding(torch.LongTensor(idx)))\n",
    "        loss_cham = chamfer_loss(y, y_pred, ps=y.shape[-1])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_cham.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch:{epoch} Batch Index:{batch_idx}\")\n",
    "            print(loss_cham.data.cpu().numpy())\n",
    "    op_schedule.step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights of the decoder\n",
    "torch.save(\n",
    "    adnet.state_dict(), DS.AUTODECODER_TRAINED_WEIGHT_DIR + \"/loaderfish_encoder01.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the AudoDecoder network on the sample LoaderFish data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adnet.eval()\n",
    "\n",
    "for batch_idx, (X, y, theta, _, idx) in enumerate(data_loader_lf_test):\n",
    "    X, y, theta = X.cuda(), y.cuda(), theta.cuda()\n",
    "    X, y, theta = Variable(X).float(), Variable(y).float(), Variable(theta).float()\n",
    "    loss_encoding, generated_encoding = find_encoding(\n",
    "        X, y, adnet, encoding_iters=300, encoding_size=256\n",
    "    )\n",
    "\n",
    "    y_pred = adnet(X, generated_encoding)\n",
    "    loss_cham = chamfer_loss(y, y_pred, ps=y.shape[-1])\n",
    "    if batch_idx % 30 == 0:\n",
    "        print(\n",
    "            f\"At batch:{batch_idx}, Chamfer Loss:{loss_cham}, Encoding Chamfer Loss:{loss_encoding}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodecoder",
   "language": "python",
   "name": "autodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
